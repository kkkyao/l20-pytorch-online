#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
MNIST-1D meta-training of a learned optimizer (coordinate-wise 2-layer LSTM)
with truncated BPTT through the optimizee trajectory (Andrychowicz et al. 2016, Eq.(3)).

What this script does (paper-aligned):
  - Sample a task from a distribution: MNIST-1D generated by different task_seed.
  - For each episode:
      * Initialize a fresh optimizee (MLP) parameters theta_0
      * Unroll K inner steps:
            g_t = ∇_theta f_t(theta_t)
            delta_t = Optimizer_phi(g_t, state_t)
            theta_{t+1} = theta_t + delta_t
      * Meta objective: sum_{t=1..K} w_t f_t(theta_t)   (Eq.(3), w_t=1 default)
      * Backprop through the unrolled computation graph (truncated BPTT) to update phi
  - Optional "drop dashed edges" first-order approximation:
      detach gradient input to the optimizer => avoids second derivatives.

Engineering notes / fixes:
  - In unroll, we must keep computation graphs needed for meta-loss.backward().
    Therefore torch.autograd.grad(loss_t, params, retain_graph=True) is REQUIRED
    if loss_t is part of meta_loss.
  - Supports torch.func.functional_call (preferred) with fallback to stateless.functional_call.
"""

import argparse
import json
import time
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Dict, Iterator, List, Optional, Tuple

import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset

from data_mnist1d import load_mnist1d

try:
    import wandb  # type: ignore
except ImportError:
    wandb = None


# ---------------- functional_call compatibility ----------------
def _get_functional_call():
    # Prefer torch.func.functional_call (no deprecation)
    try:
        from torch.func import functional_call as fc  # type: ignore
        return fc
    except Exception:
        pass
    # Fallback
    from torch.nn.utils.stateless import functional_call as fc  # type: ignore
    return fc


functional_call = _get_functional_call()


# ------------------------------- Utilities -------------------------------

def set_seed(s: int):
    np.random.seed(s)
    torch.manual_seed(s)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(s)


def to_NL(x: np.ndarray, length: int) -> np.ndarray:
    x = np.asarray(x)
    if x.ndim == 2 and x.shape[1] == length:
        return x
    if x.ndim == 3:
        if x.shape[1] == length and x.shape[2] == 1:
            return x[:, :, 0]
        if x.shape[1] == 1 and x.shape[2] == length:
            return x[:, 0, :]
    raise AssertionError(f"Unexpected x shape: {x.shape}")


def apply_norm_np(x: np.ndarray, mean: np.ndarray, std: np.ndarray, eps: float = 1e-8) -> np.ndarray:
    return (x - mean[None, :]) / (std[None, :] + eps)


def ensure_split_and_norm(
    preprocess_dir: Path,
    task_seed: int,
    xtr: np.ndarray,
    val_frac: float = 0.2,
) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """
    Ensure split.json and norm.json exist for this task_seed.
    If not, create:
      - train_idx/val_idx from xtr (which corresponds to training portion returned by load_mnist1d)
      - mean/std computed on train split only
    Returns: train_idx, val_idx, mean, std
    """
    pdir = Path(preprocess_dir) / f"seed_{task_seed}"
    pdir.mkdir(parents=True, exist_ok=True)
    split_path = pdir / "split.json"
    norm_path = pdir / "norm.json"

    n = xtr.shape[0]
    if split_path.exists() and norm_path.exists():
        with open(split_path, "r", encoding="utf-8") as f:
            split = json.load(f)
        with open(norm_path, "r", encoding="utf-8") as f:
            norm = json.load(f)
        train_idx = np.array(split["train_idx"], dtype=np.int64)
        val_idx = np.array(split["val_idx"], dtype=np.int64)
        mean = np.array(norm["mean"], dtype=np.float32)
        std = np.array(norm["std"], dtype=np.float32)
        return train_idx, val_idx, mean, std

    rng = np.random.RandomState(task_seed)
    perm = rng.permutation(n)
    v = int(round(val_frac * n))
    v = max(1, min(v, n - 1))
    val_idx = perm[:v]
    train_idx = perm[v:]

    x_train = xtr[train_idx]
    mean = x_train.mean(axis=0).astype(np.float32)
    std = x_train.std(axis=0).astype(np.float32)

    with open(split_path, "w", encoding="utf-8") as f:
        json.dump({"train_idx": train_idx.tolist(), "val_idx": val_idx.tolist()}, f, indent=2)
    with open(norm_path, "w", encoding="utf-8") as f:
        json.dump({"mean": mean.tolist(), "std": std.tolist()}, f, indent=2)

    return train_idx, val_idx, mean, std


def infinite_loader(loader: DataLoader) -> Iterator[Tuple[torch.Tensor, torch.Tensor]]:
    while True:
        for b in loader:
            yield b


# --------------------------- MLP backbone ---------------------------

def build_mlp(input_len: int = 40, num_layers: int = 5, width: int = 128) -> nn.Module:
    act_layer = nn.ReLU

    class MLPBackbone(nn.Module):
        def __init__(self, length: int):
            super().__init__()
            layers = []
            in_dim = length
            for _ in range(max(0, num_layers)):
                layers.append(nn.Linear(in_dim, width))
                layers.append(act_layer(inplace=True))
                in_dim = width
            self.mlp = nn.Sequential(*layers)
            self.out = nn.Linear(in_dim, 10)

        def forward(self, x: torch.Tensor) -> torch.Tensor:
            x = self.mlp(x)
            return self.out(x)

    return MLPBackbone(input_len)


# ---------------------- Learned Optimizer (coordinate-wise LSTM) ----------------------

class LearnedOptimizer(nn.Module):
    """
    Coordinate-wise 2-layer LSTM optimizer.

    Gradient preprocessing (paper Appendix A):
      g -> (log(|g|)/p, sign(g)) if |g| >= exp(-p)
           (-1, exp(p)*g)       otherwise

    detach_grad_input=True corresponds to "drop dashed edges" first-order approximation
    (avoid second derivatives).
    """
    def __init__(
        self,
        hidden_sz: int = 20,
        preproc: bool = True,
        preproc_factor: float = 10.0,
        detach_grad_input: bool = True,
    ):
        super().__init__()
        self.hidden_sz = int(hidden_sz)
        self.preproc = bool(preproc)
        self.preproc_factor = float(preproc_factor)
        self.preproc_threshold = float(np.exp(-self.preproc_factor))
        self.detach_grad_input = bool(detach_grad_input)

        in_dim = 2 if self.preproc else 1
        self.lstm1 = nn.LSTMCell(in_dim, self.hidden_sz)
        self.lstm2 = nn.LSTMCell(self.hidden_sz, self.hidden_sz)
        self.out = nn.Linear(self.hidden_sz, 1)

        # A small bias helps avoid "all-zero" early updates (still paper-compatible as init detail)
        nn.init.constant_(self.out.bias, 0.0)

    def _maybe_detach(self, g: torch.Tensor) -> torch.Tensor:
        return g.detach() if self.detach_grad_input else g

    def _preprocess(self, g: torch.Tensor) -> torch.Tensor:
        gg = self._maybe_detach(g)
        out = torch.zeros(gg.size(0), 2, device=gg.device, dtype=gg.dtype)
        keep = (gg.abs() >= self.preproc_threshold).view(-1)

        out[keep, 0] = (torch.log(gg[keep].abs() + 1e-8) / self.preproc_factor).view(-1)
        out[keep, 1] = torch.sign(gg[keep]).view(-1)

        out[~keep, 0] = -1.0
        out[~keep, 1] = (float(np.exp(self.preproc_factor)) * gg[~keep]).view(-1)
        return out

    def forward(self, grad_vec: torch.Tensor, hidden, cell):
        if self.preproc:
            x = self._preprocess(grad_vec)   # [N,2]
        else:
            x = self._maybe_detach(grad_vec) # [N,1]
        h0, c0 = self.lstm1(x, (hidden[0], cell[0]))
        h1, c1 = self.lstm2(h0, (hidden[1], cell[1]))
        update = self.out(h1)  # [N,1]
        return update, (h0, h1), (c0, c1)


def named_params_dict(module: nn.Module) -> Dict[str, torch.Tensor]:
    return {k: v for k, v in module.named_parameters()}


def grads_to_vector(grads: List[torch.Tensor], params: List[torch.Tensor]) -> torch.Tensor:
    vecs = []
    for g, p in zip(grads, params):
        if g is None:
            vecs.append(torch.zeros(p.numel(), device=p.device, dtype=p.dtype))
        else:
            vecs.append(g.reshape(-1))
    return torch.cat(vecs, dim=0).view(-1, 1)  # [N,1]


def vector_to_params(vec: torch.Tensor, params_template: List[torch.Tensor]) -> List[torch.Tensor]:
    outs = []
    offset = 0
    v = vec.view(-1)
    for p in params_template:
        sz = p.numel()
        outs.append(v[offset:offset + sz].view_as(p))
        offset += sz
    return outs


def clip_delta_vec(delta_vec: torch.Tensor, clip_update: float, eps: float = 1e-12):
    norm = torch.linalg.vector_norm(delta_vec.view(-1)).clamp_min(eps)
    if clip_update <= 0.0:
        coef = torch.ones((), device=delta_vec.device, dtype=delta_vec.dtype)
        return delta_vec, norm, coef
    clip_t = torch.tensor(float(clip_update), device=delta_vec.device, dtype=delta_vec.dtype)
    coef = torch.clamp(clip_t / norm, max=1.0)
    return delta_vec * coef, norm, coef


@torch.no_grad()
def eval_baseline_sgd(
    net: nn.Module,
    train_loader: DataLoader,
    test_loader: DataLoader,
    device: torch.device,
    epochs: int = 1,
    lr: float = 1e-2,
):
    m = build_mlp(input_len=40, num_layers=len([1]*5), width=128).to(device)  # placeholder
    m.load_state_dict(net.state_dict(), strict=True)
    opt = torch.optim.SGD(m.parameters(), lr=lr)
    ce = nn.CrossEntropyLoss()
    m.train()
    for _ in range(epochs):
        for xb, yb in train_loader:
            xb = xb.to(device); yb = yb.to(device)
            logits = m(xb)
            loss = ce(logits, yb)
            opt.zero_grad(set_to_none=True)
            loss.backward()
            opt.step()
    m.eval()
    correct, total, loss_sum, n = 0, 0, 0.0, 0
    for xb, yb in test_loader:
        xb = xb.to(device); yb = yb.to(device)
        logits = m(xb)
        loss = ce(logits, yb)
        loss_sum += float(loss.item()); n += 1
        pred = logits.argmax(dim=1)
        correct += int((pred == yb).sum().item())
        total += int(yb.size(0))
    return loss_sum / max(n, 1), correct / max(total, 1)


@torch.no_grad()
def eval_learned_opt(
    net: nn.Module,
    opt_net: LearnedOptimizer,
    task_train_batches: List[Tuple[torch.Tensor, torch.Tensor]],
    task_test_loader: DataLoader,
    device: torch.device,
    out_mul: float,
    clip_update: float,
):
    """
    Evaluate by running the learned optimizer for len(task_train_batches) steps starting from a fresh init,
    then test on test_loader.
    """
    ce = nn.CrossEntropyLoss()

    # fresh optimizee init
    m = build_mlp(input_len=40, num_layers=len([1]*5), width=128).to(device)  # placeholder
    m.load_state_dict(net.state_dict(), strict=True)
    params_dict = {k: v.detach().to(device).requires_grad_(True) for k, v in named_params_dict(m).items()}
    params_list_template = [params_dict[k] for k in params_dict.keys()]
    n_params = int(sum(p.numel() for p in params_list_template))
    hidden = [torch.zeros(n_params, opt_net.hidden_sz, device=device) for _ in range(2)]
    cell = [torch.zeros(n_params, opt_net.hidden_sz, device=device) for _ in range(2)]

    opt_net.eval()

    for xb, yb in task_train_batches:
        xb = xb.to(device); yb = yb.to(device)
        logits = functional_call(m, params_dict, (xb,))
        loss = ce(logits, yb)

        params_list = [params_dict[k] for k in params_dict.keys()]
        grads = torch.autograd.grad(loss, params_list, create_graph=False, retain_graph=False)
        g_vec = grads_to_vector(list(grads), params_list)
        upd_vec, h_new, c_new = opt_net(g_vec, hidden, cell)
        delta_vec = upd_vec * float(out_mul)
        delta_vec, _, _ = clip_delta_vec(delta_vec, float(clip_update))
        delta_list = vector_to_params(delta_vec, params_list)

        params_dict = {name: p + dp for (name, p), dp in zip(params_dict.items(), delta_list)}
        hidden = [h.detach() for h in h_new]
        cell = [c.detach() for c in c_new]

    # test
    m.eval()
    correct, total, loss_sum, n = 0, 0, 0.0, 0
    for xb, yb in task_test_loader:
        xb = xb.to(device); yb = yb.to(device)
        logits = functional_call(m, params_dict, (xb,))
        loss = ce(logits, yb)
        loss_sum += float(loss.item()); n += 1
        pred = logits.argmax(dim=1)
        correct += int((pred == yb).sum().item())
        total += int(yb.size(0))
    return loss_sum / max(n, 1), correct / max(total, 1)


# ------------------------------ Main ------------------------------

def main():
    ap = argparse.ArgumentParser()

    # core
    ap.add_argument("--length", type=int, default=40)
    ap.add_argument("--seed", type=int, default=0)

    # task distribution
    ap.add_argument("--task_seed_min", type=int, default=0)
    ap.add_argument("--task_seed_max", type=int, default=99)
    ap.add_argument("--val_frac", type=float, default=0.2)
    ap.add_argument("--preprocess_dir", type=str, default="artifacts/preprocess")

    # optimizee architecture
    ap.add_argument("--mlp_width", type=int, default=128)
    ap.add_argument("--mlp_layers", type=int, default=5)

    # learned optimizer
    ap.add_argument("--opt_hidden_sz", type=int, default=20)
    ap.add_argument("--opt_lr", type=float, default=1e-3)
    ap.add_argument("--out_mul", type=float, default=1e-3)
    ap.add_argument("--no_preproc", action="store_true")
    ap.add_argument("--preproc_factor", type=float, default=10.0)
    ap.add_argument("--detach_grad_input", action="store_true", help="Drop dashed edges (first-order). Recommended.")

    # truncated BPTT
    ap.add_argument("--unroll_steps", type=int, default=20, help="K steps per episode (truncation length).")
    ap.add_argument("--wt", type=float, default=1.0, help="trajectory weight w_t (default 1).")
    ap.add_argument("--clip_update", type=float, default=0.0, help="global norm clip for delta (0=off).")
    ap.add_argument("--clip_phi_grad", type=float, default=1.0, help="outer grad clipping on phi.")

    # meta training schedule
    ap.add_argument("--meta_iters", type=int, default=2000, help="number of meta-episodes (outer updates).")
    ap.add_argument("--log_every", type=int, default=50)
    ap.add_argument("--eval_every", type=int, default=200)

    # evaluation task
    ap.add_argument("--eval_task_seed", type=int, default=123)
    ap.add_argument("--eval_steps", type=int, default=200, help="number of inner steps for evaluation (train batches).")

    # wandb
    ap.add_argument("--wandb", action="store_true")
    ap.add_argument("--wandb_project", type=str, default="l2o-mnist1d")
    ap.add_argument("--wandb_group", type=str, default="mnist1d_l2o_metatrain_truncbptt")
    ap.add_argument("--wandb_run_name", type=str, default=None)

    args = ap.parse_args()

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"[INFO] device = {device}")
    set_seed(args.seed)

    run_name = (
        f"mnist1d_l2o_metatrain_seed{args.seed}_"
        f"task{args.task_seed_min}-{args.task_seed_max}_"
        f"K{args.unroll_steps}_lr{args.opt_lr}_out{args.out_mul}_"
        + datetime.now().strftime("%Y%m%d-%H%M%S")
    )
    run_dir = Path("runs") / run_name
    run_dir.mkdir(parents=True, exist_ok=True)
    print(f"[INFO] run_dir = {run_dir}")

    wandb_run = None
    if args.wandb:
        if wandb is None:
            raise RuntimeError("wandb is not installed, but --wandb was passed.")
        wandb_run = wandb.init(
            project=args.wandb_project,
            group=args.wandb_group,
            name=args.wandb_run_name or run_name,
            config=vars(args),
        )

    # architecture “template”
    net_template = build_mlp(input_len=args.length, num_layers=args.mlp_layers, width=args.mlp_width).to(device)

    opt_net = LearnedOptimizer(
        hidden_sz=args.opt_hidden_sz,
        preproc=(not args.no_preproc),
        preproc_factor=args.preproc_factor,
        detach_grad_input=bool(args.detach_grad_input),
    ).to(device)

    meta_opt = torch.optim.Adam(opt_net.parameters(), lr=args.opt_lr)
    ce = nn.CrossEntropyLoss()

    # logs
    train_log = run_dir / "meta_train_log.csv"
    eval_log = run_dir / "eval_log.csv"
    with open(train_log, "w", encoding="utf-8") as f:
        f.write("iter,task_seed,meta_loss,avg_train_loss,avg_train_acc,clip_coef\n")
    with open(eval_log, "w", encoding="utf-8") as f:
        f.write("iter,eval_task_seed,learned_test_loss,learned_test_acc,sgd_test_loss,sgd_test_acc\n")

    rng = np.random.RandomState(args.seed)
    start_time = time.time()

    # ---------------- meta-training loop ----------------
    for it in range(1, args.meta_iters + 1):
        task_seed = int(rng.randint(args.task_seed_min, args.task_seed_max + 1))

        # Load a task
        (xtr, ytr), (xte, yte) = load_mnist1d(length=args.length, seed=task_seed)
        xtr = to_NL(xtr, args.length).astype(np.float32, copy=False)
        xte = to_NL(xte, args.length).astype(np.float32, copy=False)
        ytr = np.asarray(ytr, dtype=np.int64)
        yte = np.asarray(yte, dtype=np.int64)

        train_idx, _, mean, std = ensure_split_and_norm(
            preprocess_dir=Path(args.preprocess_dir),
            task_seed=task_seed,
            xtr=xtr,
            val_frac=float(args.val_frac),
        )

        x_train = apply_norm_np(xtr[train_idx], mean, std)
        y_train = ytr[train_idx]
        x_test = apply_norm_np(xte, mean, std)
        y_test = yte

        x_train_t = torch.from_numpy(x_train)
        y_train_t = torch.from_numpy(y_train)
        x_test_t = torch.from_numpy(x_test)
        y_test_t = torch.from_numpy(y_test)

        # Episode batch stream
        gen = torch.Generator()
        gen.manual_seed(int(args.seed * 10_000 + it))  # deterministic per meta-iter
        train_loader = DataLoader(
            TensorDataset(x_train_t, y_train_t),
            batch_size=128,
            shuffle=True,
            drop_last=True,
            generator=gen,
        )
        train_iter = infinite_loader(train_loader)

        # Fresh optimizee parameters theta_0
        # We reuse the same module structure (net_template) but create a fresh param dict each episode.
        # This is the "episode starts from random init" assumption in the paper.
        fresh_net = build_mlp(input_len=args.length, num_layers=args.mlp_layers, width=args.mlp_width).to(device)
        params_dict = {k: v.detach().to(device).requires_grad_(True) for k, v in named_params_dict(fresh_net).items()}
        params_list_template = [params_dict[k] for k in params_dict.keys()]
        n_params = int(sum(p.numel() for p in params_list_template))

        # Fresh optimizer state per episode (paper-style)
        hidden = [torch.zeros(n_params, args.opt_hidden_sz, device=device) for _ in range(2)]
        cell = [torch.zeros(n_params, args.opt_hidden_sz, device=device) for _ in range(2)]

        opt_net.train()
        meta_loss = torch.zeros((), device=device)

        loss_sum_det = 0.0
        correct_det = 0
        total_det = 0
        last_clip_coef = 1.0

        # Unroll K steps and build the unrolled graph
        for t in range(1, int(args.unroll_steps) + 1):
            xb, yb = next(train_iter)
            xb = xb.to(device)
            yb = yb.to(device)

            logits = functional_call(fresh_net, params_dict, (xb,))
            loss = ce(logits, yb)

            # Eq.(3): trajectory meta objective sum_t w_t f(theta_t)
            meta_loss = meta_loss + float(args.wt) * loss

            # metrics (detached)
            with torch.no_grad():
                loss_sum_det += float(loss.item())
                pred = logits.argmax(dim=1)
                correct_det += int((pred == yb).sum().item())
                total_det += int(yb.size(0))

            # compute gradient wrt current params
            params_list = [params_dict[k] for k in params_dict.keys()]

            # IMPORTANT:
            # loss is part of meta_loss -> we MUST keep the graph for meta_loss.backward()
            # so retain_graph=True is required here.
            create_graph = (not bool(args.detach_grad_input))  # only needed if you want 2nd-order
            grads = torch.autograd.grad(
                loss,
                params_list,
                create_graph=create_graph,
                retain_graph=True,
                allow_unused=False,
            )
            g_vec = grads_to_vector(list(grads), params_list)  # [N,1]

            # optimizer step
            upd_vec, h_new, c_new = opt_net(g_vec, hidden, cell)
            delta_vec = upd_vec * float(args.out_mul)

            delta_vec, _, coef = clip_delta_vec(delta_vec, float(args.clip_update))
            last_clip_coef = float(coef.detach().item())

            delta_list = vector_to_params(delta_vec, params_list)
            params_dict = {name: p + dp for (name, p), dp in zip(params_dict.items(), delta_list)}

            hidden = list(h_new)
            cell = list(c_new)

        # Outer update on phi
        meta_opt.zero_grad(set_to_none=True)
        meta_loss.backward()
        if args.clip_phi_grad and float(args.clip_phi_grad) > 0.0:
            torch.nn.utils.clip_grad_norm_(opt_net.parameters(), max_norm=float(args.clip_phi_grad))
        meta_opt.step()

        avg_train_loss = loss_sum_det / max(int(args.unroll_steps), 1)
        avg_train_acc = correct_det / max(total_det, 1)

        with open(train_log, "a", encoding="utf-8") as f:
            f.write(f"{it},{task_seed},{float(meta_loss.item()):.8f},{avg_train_loss:.8f},{avg_train_acc:.6f},{last_clip_coef:.6g}\n")

        if wandb_run is not None:
            wandb.log(
                {
                    "iter": it,
                    "task_seed": task_seed,
                    "meta_loss": float(meta_loss.item()),
                    "train/avg_loss": avg_train_loss,
                    "train/avg_acc": avg_train_acc,
                    "clip/coef": last_clip_coef,
                    "time/elapsed_sec": time.time() - start_time,
                }
            )

        if it % int(args.log_every) == 0:
            print(
                f"[META it={it}] task_seed={task_seed} "
                f"meta_loss={float(meta_loss.item()):.4f} avg_train={avg_train_loss:.4f} acc={avg_train_acc:.4f}"
            )

        # periodic evaluation on a held-out task
        if it % int(args.eval_every) == 0:
            eval_seed = int(args.eval_task_seed)
            (xtr_e, ytr_e), (xte_e, yte_e) = load_mnist1d(length=args.length, seed=eval_seed)
            xtr_e = to_NL(xtr_e, args.length).astype(np.float32, copy=False)
            xte_e = to_NL(xte_e, args.length).astype(np.float32, copy=False)
            ytr_e = np.asarray(ytr_e, dtype=np.int64)
            yte_e = np.asarray(yte_e, dtype=np.int64)

            train_idx_e, _, mean_e, std_e = ensure_split_and_norm(
                preprocess_dir=Path(args.preprocess_dir),
                task_seed=eval_seed,
                xtr=xtr_e,
                val_frac=float(args.val_frac),
            )

            x_train_e = apply_norm_np(xtr_e[train_idx_e], mean_e, std_e)
            y_train_e = ytr_e[train_idx_e]
            x_test_e = apply_norm_np(xte_e, mean_e, std_e)
            y_test_e = yte_e

            x_train_e_t = torch.from_numpy(x_train_e)
            y_train_e_t = torch.from_numpy(y_train_e)
            x_test_e_t = torch.from_numpy(x_test_e)
            y_test_e_t = torch.from_numpy(y_test_e)

            gen_e = torch.Generator()
            gen_e.manual_seed(int(args.seed * 999 + it))
            eval_train_loader = DataLoader(
                TensorDataset(x_train_e_t, y_train_e_t),
                batch_size=128,
                shuffle=True,
                drop_last=True,
                generator=gen_e,
            )
            eval_test_loader = DataLoader(
                TensorDataset(x_test_e_t, y_test_e_t),
                batch_size=512,
                shuffle=False,
            )

            # Build a fixed list of evaluation train batches (eval_steps)
            eval_train_iter = infinite_loader(eval_train_loader)
            eval_batches = [next(eval_train_iter) for _ in range(int(args.eval_steps))]

            learned_test_loss, learned_test_acc = eval_learned_opt(
                net=build_mlp(input_len=args.length, num_layers=args.mlp_layers, width=args.mlp_width).to(device),
                opt_net=opt_net,
                task_train_batches=eval_batches,
                task_test_loader=eval_test_loader,
                device=device,
                out_mul=float(args.out_mul),
                clip_update=float(args.clip_update),
            )

            # SGD baseline (same number of epochs is not directly comparable; here we use 1 epoch as a reference)
            sgd_test_loss, sgd_test_acc = eval_baseline_sgd(
                net=build_mlp(input_len=args.length, num_layers=args.mlp_layers, width=args.mlp_width).to(device),
                train_loader=eval_train_loader,
                test_loader=eval_test_loader,
                device=device,
                epochs=1,
                lr=1e-2,
            )

            with open(eval_log, "a", encoding="utf-8") as f:
                f.write(f"{it},{eval_seed},{learned_test_loss:.8f},{learned_test_acc:.6f},{sgd_test_loss:.8f},{sgd_test_acc:.6f}\n")

            print(
                f"[EVAL it={it} seed={eval_seed}] learned: test={learned_test_loss:.4f}/{learned_test_acc:.4f} "
                f"| sgd: test={sgd_test_loss:.4f}/{sgd_test_acc:.4f}"
            )

            if wandb_run is not None:
                wandb.log(
                    {
                        "eval/iter": it,
                        "eval/learned_test_loss": learned_test_loss,
                        "eval/learned_test_acc": learned_test_acc,
                        "eval/sgd_test_loss": sgd_test_loss,
                        "eval/sgd_test_acc": sgd_test_acc,
                    }
                )

    if wandb_run is not None:
        wandb_run.finish()

    print(f"[DONE] meta_iters={args.meta_iters} logs in: {run_dir}")


if __name__ == "__main__":
    main()
